<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8"/>
    <title>Texan Turnout</title>
    <link rel="stylesheet" href="tufte.css"/>
    <link rel="stylesheet" href="latex.css"/>
    <meta name="viewport" content="width=device-width, initial-scale=1">
  </head>

  <body>
    <article>
<h1 id="tx-turnout">TexanTurnout</h1>
<h2> Predicting Voter Turnout Rates in Texas Elections</h2>
      <p class="subtitle"><a href="http://chalence.github.io">Chalence Safranek-Shrader</a></p>
<section>

        <div class="epigraph">
          <blockquote>
            <p>Every election is determined by the people who show up.</p>
            <footer>Larry J. Sabato, “Pendulum Swing”</footer>
	  </blockquote>
	  </div>
	  </section>

	        <section>
        <h2 id="introduction">Trying to Flip a Vote?</h2>
	  
	  <p>You'll need to know who is most likely to turn up at the polls.  Any sort of election prediction analysis requires an estimate of the fraction of registered voters who will actually go to the polls and cast a vote — i.e., the voter turnout rate. This voter fraction, calibrated with registration statistics and pre-election polling figures, provides political campaigns and politically-minded organizations with a probable result of future elections, and how close any given race will be. They can then determine how to best allocate time and funding, where get-out-the-vote campaigns are most needed (or not necessary), and set the overall communication strategy with their members.</p>

	  <p>Traditionally, determining how many people will actually vote is done with pre-election polling. However, direct polling is expensive and slow, and prone to a slew of random and systematic errors. The efficacy of direct phone-based polling has <a href="https://www.nytimes.com/2015/06/21/opinion/sunday/whats-the-matter-with-polling.html?_r=0">plummeted</a> thanks to the proliferation of cell phones and caller-id. Instead, predicting expected voter turnout rates from pre-existing, and mostly public, data represents a far more accurate and efficient approach.
	  </p>

<p>As a fellow at the <a href="http://insightdatascience.com/">Insight Data Science Program</a> in the Fall of 2017, I partnered with <a href="https://www.valuevoting.com/">Value Voting</a> to improve their prediction model for future voter turnout rates. Value Voting works with a variety of progressive, Texas-based organizations to advise where coordinated outreach campaigns will be most effective. By cross-referencing a group's member list with upcoming election figures, Value Vote identifies the districts in which an organization has significant political sway via an interactive user-friendly dash board. Value Voting delivers processed member lists that quantify individual members voting 'power', a metric of how likely someone is to vote, which organizations use to develop microtargeted communication strategies and maximize the impact of their resources. While the examples in this analysis are Texas-based, this approach can be applied to any of the 50 states.</p>

<!--
<p>  In this post, I will describe the work I did with Value Voting to help improve their methodology to predict overall voter turnout rates. In particular, I will highlight two different approaches to this challenge: one based on the individual level, where predicting whether a given person will vote or not is based on demographics and past voting history. In a complementary approach, I take a different view by examining factors specific to a given election which correlate with changes in the overall voter turnout rate. </p>
-->

<p>
With one week to improve Value Voting's voter turnout prediction methodology, I used individual demographics and past election records to deliver a model with a 7 percent increase in voter prediction accuracy. While doing so, I also identified some major confounding factors that limit the accuracy of these approaches to predict future election turnout and how these elements may influence any given election.
</p>

      </section>



      <section>
<h2 id="getting-started">Exploring the Data</h2>

<p>
Value Voting supplied me with the 2016 voter registration role for the state of Texas, which includes the voter registration details for 14+ million Texans. Importantly, the data also included past election participation, for general & presidential (2008, 2012, 2016, etc.), midterm (2010, 2012, etc.) and primary elections. While voter registration, name, address, and past participation is publicly available, the dataset also included a number of externally sourced & engineered features, such as cell phone number, number of people in household, race, and gender.
</p>


<p>
I was additionally given a high-level summary of every past Texas election (Federal, State, & primaries), which included winner votes, runner-up votes, and total number of candidates running. For Texas State House and Senate primary races, I supplemented this election summary with other publicly available data, such as the total funds spent by various candidates.
</p>



<p>
I started by looking for high-level insights that would indicate any potential demographic patterns, a straightforward comparison of trends between overall voter turnout rate and demographic groups. For example, analyzing the overall voter turnout by age group produces this plot:
</p>

        <figure>
          <label for="mn-exports-imports" class="margin-toggle">&#8853;</label><input type="checkbox" id="mn-exports-imports" class="margin-toggle"/><span class="marginnote">Voter turnout rate in the 2016 general election broken down by age group.</span>
          <img src="images/age_turnout.png" alt="age-turnout" />
        </figure>


<p>Unsurprisingly, people below the age of 30 tend to vote less than older people, though the trend does begin to turn over for people older than 70.</p>


        <figure>
          <label for="mn-exports-imports" class="margin-toggle">&#8853;</label><input type="checkbox" id="mn-exports-imports" class="margin-toggle"/><span class="marginnote">Voter turnout rate in the 2016 general election broken number of previous votes cast in general elections since 2000</span>
          <img src="images/turnout_nvotes.png" alt="age-turnout" />
</figure>


<p>As seen above, voter turnout also depends strongly on a given person’s voting history — people who voted in the past will tend to do so again, where voter turnout rate is segmented based on the number of previous votes (since 2000) someone has participated in<label for="sn-in-his-later-books" class="margin-toggle sidenote-number"></label> <span class="sidenote">This also conflates age with turnout rate, though — someone who has been able to vote in 6 votes as of 2016 must have been born in or before 1986 </span>.</p>


<p>Finally, while analyzing the data, it also became clear that different districts (Federal and State) have large differences in the voter turnout rate. This could be due to a number of reasons -- different levels of enthusiasm for a given race, overall socioeconomic status, differences between ethnic groups, access to voting locations, etc. Since Value Voting is primarily interested in the voter turnout rate within individual districts, and I didn't have immediate access to this supplementary data, it made sense to separate this analysis by district, opposed to combining them all into a single model.
</p>


</section>

      <section>
        <h2 id="demographics">Demographics-Based Approach</h2>

<p>
For my first approach to this problem, I opted for to focus on voter demographics. Here, I treat individual voters as the datapoints, and I classify whether they will vote or not in a future election based on their demographic features (age, sex, party affiliation) and their past voting history.
</p>

<p>
While this is a relatively straightforward binary classification problem, the main challenge lies in how to compress a person’s potentially complex voting history (composed of state and presidential primaries, and general elections) to one or a few meaningful quantitative features. I experimented with a number of approaches:
<ul>
<li>Last1: Did a person vote in the previous election?</li> 
<li>LastX: Of the last X votes, how many did they vote in?</li>
<li>Voting fraction: of the number of votes a person has been eligible for, what fraction did they vote in? </li>
<li>Voting fraction + tscore: Here tscore is a quantitive value between 0 and 1 which expresses how recently a person’s votes have been<label for="sn-in-his-later-books" class="margin-toggle sidenote-number"></label> <span class="sidenote">For example is someone voted in 2014, but not in 2016, their voting fraction would be 0.5, but with a tscore of 0. The reverse -- voted 2016, not 2014 -- would result in a tscore of 1.  </span> </li>
  <li>Individual binary 0 & 1 labels for each individual type of vote and how many votes ago in the past it was. </li>
 </ul>
</p>

<p>
There is not too much difference between these approaches: all voting history features produce accuracies within 5% of each other. Overall, though, I find LastX with X=2 to produce near the best classification rates, and has the advantage of being relatively simple to understand and compute. Specifically, Last2 is the number of votes in the last two similar elections (midterm, primary, presidential) compared with the target variable.
</p>

<p>
For the classification, I began with logistic regression. It is fast to train, and highly interpretable. Overall, this dataset has many, many more samples than it does features (and potential combination of features), and thus the particular choice of algorithm did not significantly matter --- other more complex classification algorithms (random forest, SVM, etc.) did not produce significantly different levels of accuracy.
</p>


<p>
Here I will focus on the prediction of Federal House races, though in principle this methodology would apply to any election: I train the model on whether or not someone voted in 2012 based on their past election activtiy. For validation, I test both on held-out 2012 data for use in tuning the model, and on 'unseen' 2016 election data, to gauge how well the model performs when working to predict future results. Primarily because past voting activity is such a good indicator of future activity, this approach does a fairly good job at predicting voter turnout. Overall, this model achieves accuracies of 78% for 2012 data, and 70% for the 2016 figures<label for="sn-in-his-later-books" class="margin-toggle sidenote-number"></label> <span class="sidenote">If I restrict my data to people with earlier voter registration dates, such that they have the opportunity to have a full Last2 score, the model accuracy jumps by nearly 10%  </span>; the F1 score, representing the harmonic mean of precision and recall, is 0.81.
</p>

<p>
Along with a no vote/vote classification, logistic regression also supplies the confidence, in the form of a probability, of its prediction. The probability that someone is going to vote turns out to be an extremely useful metric for Value Voting and its customers since it enables microtargeting. Voter microtargeting is a deliberate focus on individual people or groups by political organizations based on their expected vote or propensity to visit the polls. For example, some organizations may wish to only reach out to those who are almost certain to vote in a forthcoming election, while other outreach campaigns may instead wish to target those on the fence about voting in an effort to increase turnout. If we classify ‘likely voters’ as those with a probability of voting (PV) of PV > 0.9, and ‘on the fence’ voters as those with 0.3 < PV < 0.6, we can immediately understand the characteristics of these two groups by segmenting our dataset.</p>
<p>
Likely voters:
<ul>
<li>Average age of 60</li>
<li>88% registered Democrats and Republicans</li>
<li>Have voted an average of 84% of the time they’ve been eligible</li>
</ul>
<p>
On-the-fence voters:
</p>
<ul>
<li>Average age of 43</li>
<li>66% unaffiliated with a political party</li>
<li>Have only voted an average of 0.6 times</li>
</ul>


<p>
Unfortunately, though, my goal here was to produce a model which exceeded Value Voting's current working model for the voter turnout rate -- one where the voting turnout rate does not change. Since the previous turnout rate effectively already encapsulates demographic information and voting history information, a demographics based approach represents a negligible improvement with respect predicting the overall voter turnout rate. I must attack this problem from a different angle.
<!..My model would only formally be better if demograhpics  

simply using the past voting turnout rate for a similar election (midterm or presidential) is a fairly good approach in the . Adding in additional demograph .
-->
</p>



</section>



      <section>
<h2 id="getting-started">Election-Based Approach</h2>

<p>
To combat the limitation with the demographic-based attack plan described above, I opted for an approach based on broader, election-based characteristics to see if there were certain features that could be used to build a predictive model for the voter turnout rates. Using the corpus of 2012, 2014, and 2016 Texas-state House and Senate races<label for="sn-in-his-later-books" class="margin-toggle sidenote-number"></label> <span class="sidenote">Texas districts were redrawn in 2012, thus making extending this analysis back a much more complex endeavor.  </span>, I began to see if there was a correlation between the competitiveness of a race and the voter turnout race:
</p>

        <figure>
          <label for="mn-exports-imports" class="margin-toggle">&#8853;</label><input type="checkbox" id="mn-exports-imports" class="margin-toggle"/><span class="marginnote"> 2016 House of Representatives Primary & General vote turnout rate broken down by district and victory margin.</span>
          <img src="images/margin_turnout_scatter.png" alt="vmargin-turnout" />
        </figure>

<p>
Here, I'm showing a scatter plot of the voter turnout rate vs. vote margin for different election districts. Here, vote margin (which I use as a proxy for competitiveness) is the percent difference  of received votes between the race victor and the runner up, such that 0% would be a tie, and 100% is an uncontested race. There doesn’t seem to be much of a correlation, which came as a surprise: I would naively have expected close, competitive races to have attracted more people to the polls in a particular district.
</p>

<p>
However, different districts, with varied demographics (age distribution, income, density, etc.), likely have overall base voter turnout levels which may muddy the above analysis. Next, I took the districts which had the largest changes in voter turnout rates, to see if I could isolate what caused the change. Here is the voter turnout <i>change</i> between the 2012 and 2016 general election based on the competiveness of the equivalent 2012 election:
</p>

10.0,0.0,10.0,50.0,80,110.0
        <figure>
          <label for="mn-exports-imports" class="margin-toggle">&#8853;</label><input type="checkbox" id="mn-exports-imports" class="margin-toggle"/><span class="marginnote">The change in the voter turnout rate in Texas State House and Senate primary races, broken up by the vote margin of the <i>previous</i> 2012 election. Very close races correspond to a vote margin of 0-10%, close is 10-50%, safe is 50-99%, and uncontested races are defined to have a 100% vote margin.  Note: overall, election turnout increased from 2012 to 2016.</span>
          <img src="images/turnout_change_margin.png" alt="vmargin-turnout" />
        </figure>

<p>
Uncontested 2012 races see a 2012&rarr;2016 voter increase which is 55% greater than non-uncontested races in 2016. One may understand this as follows: uncontested seats in a given year have a significantly higher chance of becoming contested by a serious candidate the following election year. These new candidates, seeing a potential opening, conduct widespread campaigns, spend more money on average, and thus produce a surge in the number of votes cast.
</p>


<p>
While this relationship is noisy, from this starting point I was able to
build a regression model, predicting the change in the voter turnout rate from the previous voter turnout margin and a number of other features (number of candidates, previous total votes cast, etc.). After feature scaling, a 2nd degree polynomial model fit the held-out test data the best. The overall R^2 for the fit is 0.48 — given the range of complex political and societal factors which likely impact the voter turnout rate, it is surprising that such a simple model is able to, loosely speaking, explain 48% of the variance.
</p>


<p>
From Value Voting's business perspective, the most interesting metric is how much better, or worse, this model preforms compared with their preexisting model where voter turnout rates are assumed to be static --- we will express this in terms of the total vote error. Restricting ourself to the 2016 Texas State House and Senate primary races, the static model misclassified 1.97 million voters, while the model here reduced this misclassification by 290,000 people to 1.68 million voters. Given there were a total of 4.1 million votes in these elections, my model represents an improvement of roughly 7%.
</p>


<!--
<p>
Due to the nature of the data and the problem, there are a number of issues with this model. There are a relatively small number (<1000) of training data points. A

Too many missing data points -- if there wasn't a primary the year before, th (for exa Not able to test properly on future, unseen years. And it will benefit greatly from as time progresses and new elections occur, effectively giving us more training data. It will also be crucial to examine how this model performs on the 2018 election. Importantly, given that this model is only able to to be trained on two elections (2014 and 2016), one presidential and one midterm.
</p>
-->



</section>


      <section>
<h2 id="getting-started">Afterthoughts</h2>

<p>
One of the key difficulties in this project, or any predictive analysis using election data, is the human factor. People are finicky creatures, and frequently make choices on whims, often inconsistently compared with their past behaviors. Elections and attitudes towards them, too, are complex beasts. Perhaps a certain candidate’s message (or lack thereof) causes a surge in interest & enthusiasm. Or a wealthy donor decides to flip a race and buys significant airtime. Or a certain county <a href="https://www.thenation.com/article/there-are-868-fewer-places-to-vote-in-2016-because-the-supreme-court-gutted-the-voting-rights-act/">reduces the number of polling stations</a>. Biggest takeaway: predicting elections and human behavior is a <a href="http://blog.drivendata.org/2016/12/21/election-data/">difficult data science task</a>, fraught with uncertainties based around constantly shifting political ideas and attitudes. Indeed, if the most recent general election was any indication, predictions can be, unfortunately, very wrong. In spite of the challenges, I have built models based both on the demographics of an electorate, and features specific to elections, which are able to do a, and, hopefully bring some business value to Value Voting. The ultimate tests of these models can't be done yet, sadly, because the ground truth does not exist yet --- we've got to wait until 2018 and beyond.
</p>


<p>
Given more time, it would be interesting to understand & quantify the broader political factors which directly impact voter turnout rates. As a concrete example, the 2010 midterm election after President Obama’s election saw voter turnout rates surge among registered republicans, particularly in primary contests. This is generally understood as due to the rise of the Tea Party movement and backlash towards Obama’s fiscal policies. Using this as a rough guide, it seems safe to say voter turnout rates, particularly among democrats, will similarly surge in the 2018 midterm elections, with voters electrified in opposition to Donald Trump’s unique blend of populism and crass. The models I presented above are not designed to detect such a surge. However, it seems likely that by utilizing some combination of polling data, text-mining, and sentiment analysis of Tweets, Facebook posts, news articles, etc., data science could understand these overt political trends, and perhaps eventually exceed the foresight of even the most astute political observers.
</p>



</section>




      <section>
        <h2 id="epilogue">Contact</h2>
<p>Feel free to reach out to Chalence at: <a href="mailto:csafranek@gmail.com">csafranek@gmail.com</a> or <a href="http://chalence.github.io">here</a></p>

</section>



</article>


  </body>
</html>
